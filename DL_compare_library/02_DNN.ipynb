{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library import\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, InputLayer\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\korbsl\n"
     ]
    }
   ],
   "source": [
    "print(os.path.expanduser('~'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\korbsl\\\\OneDrive - SAS\\\\Backup\\\\500_Practice\\\\20_Python\\\\1_Deep_learning\\\\VDMML_training'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_base = os.getcwd()\n",
    "path_base\n",
    "# os.listdir(path_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'C:\\\\Users\\\\korbsl\\\\OneDrive - SAS\\Backup\\\\500_Practice\\\\10_SAS\\\\1_Deep_learning\\\\vdmml_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas로 csv file 호출\n",
    "train_develop = pd.read_csv(file_path+'\\\\train_develop.csv', sep=',', header=0)\n",
    "valid_develop = pd.read_csv(file_path+'\\\\valid_develop.csv', sep=',', header=0)\n",
    "test_develop  = pd.read_csv(file_path+'\\\\test_develop.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 데이터 형태 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AcctAge</th>\n",
       "      <th>DDA</th>\n",
       "      <th>DDABal</th>\n",
       "      <th>CashBk</th>\n",
       "      <th>Checks</th>\n",
       "      <th>DirDep</th>\n",
       "      <th>NSF</th>\n",
       "      <th>NSFAmt</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Teller</th>\n",
       "      <th>...</th>\n",
       "      <th>Moved</th>\n",
       "      <th>InArea</th>\n",
       "      <th>Ins</th>\n",
       "      <th>Branch</th>\n",
       "      <th>Res</th>\n",
       "      <th>Dep</th>\n",
       "      <th>DepAmt</th>\n",
       "      <th>Inv</th>\n",
       "      <th>InvBal</th>\n",
       "      <th>_PartInd_</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>part</th>\n",
       "      <th>row</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">train</th>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1986.81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>B2</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>446.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B3</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">valid</th>\n",
       "      <th>0</th>\n",
       "      <td>6.7</td>\n",
       "      <td>1</td>\n",
       "      <td>2813.45</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B1</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>1208.94</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>190.03</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>B14</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>880.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">test</th>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>419.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B17</td>\n",
       "      <td>R</td>\n",
       "      <td>2</td>\n",
       "      <td>1170.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1594.84</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>B1</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1144.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AcctAge  DDA   DDABal  CashBk  Checks  DirDep  NSF  NSFAmt  Phone  \\\n",
       "part  row                                                                      \n",
       "train 0        0.7    1  1986.81       0       1       1    0    0.00      0   \n",
       "      1        4.1    0     0.00       0       0       0    0    0.00      0   \n",
       "valid 0        6.7    1  2813.45       0       2       0    0    0.00      0   \n",
       "      1        0.8    1   190.03       0       1       0    1    5.65      0   \n",
       "test  0        0.3    1   419.27       0       0       0    0    0.00      0   \n",
       "      1        0.5    1  1594.84       0       1       0    0    0.00      0   \n",
       "\n",
       "           Teller  ...  Moved  InArea  Ins  Branch  Res  Dep   DepAmt  Inv  \\\n",
       "part  row          ...                                                       \n",
       "train 0         0  ...      0       1    0      B2    R    1   446.93    0   \n",
       "      1         0  ...      0       1    1      B3    S    0     0.00    0   \n",
       "valid 0         5  ...      0       1    1      B1    S    2  1208.94    0   \n",
       "      1         0  ...      0       1    0     B14    S    3   880.25    0   \n",
       "test  0         0  ...      0       1    1     B17    R    2  1170.06    0   \n",
       "      1         1  ...      0       1    0      B1    S    1  1144.24    0   \n",
       "\n",
       "           InvBal  _PartInd_  \n",
       "part  row                     \n",
       "train 0       0.0          1  \n",
       "      1       0.0          1  \n",
       "valid 0       0.0          2  \n",
       "      1       0.0          2  \n",
       "test  0       0.0          0  \n",
       "      1       0.0          0  \n",
       "\n",
       "[6 rows x 49 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train, valid, test set head 출력\n",
    "pd.concat([train_develop.head(2)\n",
    "        ,valid_develop.head(2)\n",
    "        ,test_develop.head(2)], axis=0, keys=['train','valid','test'], names=['part','row'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "variable type & final data file 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "### data import code\n",
    "\n",
    "def data_import(in_df):\n",
    "    \n",
    "#     path = 'C:\\\\beom\\\\_final_folder\\\\04_training\\\\01_VDMML\\\\1_deeplearning\\\\DL_VDMML_EXAM_DATA\\\\'\n",
    "    path = file_path\n",
    "    df = in_df\n",
    "    \n",
    "    # pandas로 csv file 호출\n",
    "    df = pd.read_csv((path+'\\\\'+df+'.csv'), sep=',', header=0)\n",
    "\n",
    "    # 변수 형태가 잘못 들어간 case 변경\n",
    "    cat_vars = ['Branch','Res','Ins','DDA','DirDep','NSF','Sav','ATM','CD','IRA'\n",
    "                    ,'LOC','ILS','MM','MTG','CC','SDB','HMOwn','Moved','InArea','Inv']\n",
    "    for x in cat_vars:\n",
    "        df[x] = df[x].astype(str)\n",
    "    \n",
    "    # 변수 유형별 리스트 셋 정의\n",
    "    feature_list = [name for name in df.columns if (name !='Ins')&(name !='_PartInd_')]\n",
    "    cat_vars = df.columns[(df.dtypes=='object')&(df.columns !='Ins')&(df.columns !='_PartInd_')]\n",
    "    num_vars = [name for name in df.columns if (name not in cat_vars)&(name !='Ins')&(name !='_PartInd_')]\n",
    "\n",
    "    # categorical data를 dummy로 변경\n",
    "    x_dummy = pd.get_dummies(df[cat_vars], prefix_sep='_')\n",
    "#     y_dummy = pd.get_dummies(df['Ins'], drop_first=True)\n",
    "    y_dummy = pd.get_dummies(df['Ins'], prefix_sep='_')\n",
    "    \n",
    "    # numeric variable standardization\n",
    "    df[num_vars] = (df[num_vars] - np.mean(df[num_vars], axis=0)) / np.std(df[num_vars], axis=0)\n",
    "\n",
    "    # 최종 X, Y data set 생성\n",
    "    out_x = np.c_[df[num_vars].values, x_dummy.values].astype(np.float64)\n",
    "    out_y = y_dummy.values.ravel()\n",
    "    \n",
    "    # 모든 변수 이름\n",
    "    feature_names = num_vars + x_dummy.columns.tolist()\n",
    "    \n",
    "    return out_x, out_y, feature_names\n",
    "\n",
    "train_x = data_import(in_df='train_develop')[0]\n",
    "train_y = data_import(in_df='train_develop')[1]\n",
    "\n",
    "valid_x = data_import(in_df='valid_develop')[0]\n",
    "valid_y = data_import(in_df='valid_develop')[1]\n",
    "\n",
    "test_x = data_import(in_df='test_develop')[0]\n",
    "test_y = data_import(in_df='test_develop')[1]\n",
    "\n",
    "feature_names = data_import(in_df='train_develop')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.653632\n",
       "1    0.346368\n",
       "Name: Ins, dtype: float64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_develop.Ins.value_counts()/train_develop.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create Deep learning architecture "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-1. using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 모델 구성\n",
    "\n",
    "tf.reset_default_graph() \n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "dropout_rate = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "W1 = tf.get_variable(\"W1\", shape=[len(feature_names), 30], initializer=tf.contrib.layers.xavier_initializer())\n",
    "W2 = tf.get_variable(\"W2\", shape=[30, 20], initializer=tf.contrib.layers.xavier_initializer())\n",
    "W3 = tf.get_variable(\"W3\", shape=[20, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "W4 = tf.get_variable(\"W4\", shape=[10,  5], initializer=tf.contrib.layers.xavier_initializer())\n",
    "W5 = tf.get_variable(\"W5\", shape=[5,   1])\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([30]), name=\"b1\")\n",
    "b2 = tf.Variable(tf.zeros([20]), name=\"b2\")\n",
    "b3 = tf.Variable(tf.zeros([10]), name=\"b3\")\n",
    "b4 = tf.Variable(tf.zeros([ 5]), name=\"b4\")\n",
    "b5 = tf.Variable(tf.zeros([ 1]), name=\"b5\")\n",
    "\n",
    "L1 = tf.add(tf.matmul(X,W1),b1)\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.dropout(L1, dropout_rate)\n",
    "\n",
    "L2 = tf.add(tf.matmul(L1,W2),b2)\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.dropout(L2, dropout_rate)\n",
    "\n",
    "L3 = tf.add(tf.matmul(L2,W3),b3)\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.dropout(L3, dropout_rate)\n",
    "\n",
    "L4 = tf.add(tf.matmul(L3,W4),b4)\n",
    "L4 = tf.nn.relu(L4)\n",
    "L4 = tf.nn.dropout(L4, dropout_rate)\n",
    "\n",
    "Lout = tf.add(tf.matmul(L4,W5),b5)\n",
    "\n",
    "\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=Lout))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01, beta1=0.9, beta2=0.999)\n",
    "train_op = optimizer.minimize(cost, global_step=tf.train.get_global_step())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_summ = tf.summary.scalar(\"Cost\", cost)\n",
    "\n",
    "correct = tf.equal(tf.argmax(Lout, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "accuracy_summ = tf.summary.scalar(\"Accuracy\", accuracy, [\"Epoch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs_completed = 0\n",
    "index_in_epoch = 0\n",
    "\n",
    "# for splitting out batches of data\n",
    "def next_batch(batch_size, X_data, Y_data):\n",
    "    \n",
    "    num_examples = X_data.shape[0]\n",
    "\n",
    "    global X_train\n",
    "    global y_train\n",
    "    global index_in_epoch\n",
    "    global epochs_completed\n",
    "\n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "\n",
    "    # when all trainig data have been already used, it is reorder randomly    \n",
    "    if index_in_epoch > num_examples:\n",
    "        # finished epoch\n",
    "        epochs_completed += 1\n",
    "        # shuffle the data\n",
    "        perm = np.arange(num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        X_data = X_data[perm]\n",
    "        Y_data = Y_data[perm]\n",
    "        # start next epoch\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "        assert batch_size <= num_examples\n",
    "    end = index_in_epoch\n",
    "    return X_data[start:end], Y_data[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    tf.global_variables_initializer().run()\n",
    "    merged = tf.summary.merge_all()\n",
    "    epoch_merged = tf.summary.merge_all(\"Epoch\")\n",
    "    batch_size = int(train_develop.shape[0]/100)\n",
    "    writer = tf.summary.FileWriter(\"./logs\", sess.graph)\n",
    "\n",
    "    for epoch in range(1):\n",
    "        for step in range(batch_size):\n",
    "            train, label = next_batch(100, train_x, train_y)\n",
    "        \n",
    "            summ, _ = sess.run([merged, train_op], feed_dict={X: train,\n",
    "                                                          Y: label,\n",
    "                                                          dropout_rate: 0.05})\n",
    "            writer.add_summary(summ, epoch * batch_size + step)\n",
    "            \n",
    "        summ, _accuracy = sess.run([epoch_merged, accuracy],\n",
    "                                          feed_dict={X: test_x,\n",
    "                                                     Y: test_y,\n",
    "                                                     dropout_rate: 0.05}) \n",
    "        writer.add_summary(summ, (epoch + 1) * batch_size)\n",
    "        print (\"Epoch:\", (epoch + 1))\n",
    "#         print (\"Test Accuracy:\", _accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'next_batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-2c3987650d24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             summ, _ = sess.run([merged, train_op], feed_dict={X: train,\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'next_batch'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    merged = tf.summary.merge_all()\n",
    "    epoch_merged = tf.summary.merge_all(\"Epoch\")\n",
    "    writer = tf.summary.FileWriter(\"./logs\", sess.graph)\n",
    "    \n",
    "    batch_size = int(train_develop.shape[0]/100)\n",
    "    \n",
    "    for epoch in range(1):\n",
    "        for step in range(batch_size):\n",
    "            train = train_x.next_batch(100)\n",
    "            label = train_y.next_batch(100)\n",
    "            summ, _ = sess.run([merged, train_op], feed_dict={X: train,\n",
    "                                                           Y: label,\n",
    "                                                           dropout_rate: 0.05})\n",
    "            writer.add_summary(summ, epoch * batch_size + step)\n",
    "        \n",
    "        summ, _accuracy = sess.run([epoch_merged, accuracy],\n",
    "                                          feed_dict={X: test_x,\n",
    "                                                     Y: test_y,\n",
    "                                                     dropout_rate: 0.05}) \n",
    "        writer.add_summary(summ, (epoch + 1) * batch_size)\n",
    "        \n",
    "        print \"Epoch:\", (epoch + 1)\n",
    "        print \"Test Accuracy:\", _accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "for step in range(2):\n",
    "    sess.run(train_op, feed_dict={X: train_x, Y: train_y})\n",
    "\n",
    "    if (step + 1) % 10 == 0:\n",
    "        print(step + 1, sess.run(cost, feed_dict={X: train_x, Y: train_y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# 첫번째 가중치의 차원은 [특성, 히든 레이어의 뉴런갯수] -> [2, 10] 으로 정합니다.\n",
    "W1 = tf.Variable(tf.random_uniform([len(feature_names), 10], -1., 1.))\n",
    "# 두번째 가중치의 차원을 [첫번째 히든 레이어의 뉴런 갯수, 분류 갯수] -> [10, 3] 으로 정합니다.\n",
    "W2 = tf.Variable(tf.random_uniform([10, 2], -1., 1.))\n",
    "\n",
    "# 편향을 각각 각 레이어의 아웃풋 갯수로 설정합니다.\n",
    "# b1 은 히든 레이어의 뉴런 갯수로, b2 는 최종 결과값 즉, 분류 갯수인 3으로 설정합니다.\n",
    "b1 = tf.Variable(tf.zeros([10]))\n",
    "b2 = tf.Variable(tf.zeros([2]))\n",
    "\n",
    "# 신경망의 히든 레이어에 가중치 W1과 편향 b1을 적용합니다\n",
    "L1 = tf.add(tf.matmul(X, W1), b1)\n",
    "L1 = tf.nn.relu(L1)\n",
    "\n",
    "# 최종적인 아웃풋을 계산합니다.\n",
    "# 히든레이어에 두번째 가중치 W2와 편향 b2를 적용하여 3개의 출력값을 만들어냅니다.\n",
    "model = tf.add(tf.matmul(L1, W2), b2)\n",
    "\n",
    "# 텐서플로우에서 기본적으로 제공되는 크로스 엔트로피 함수를 이용해\n",
    "# 복잡한 수식을 사용하지 않고도 최적화를 위한 비용 함수를 다음처럼 간단하게 적용할 수 있습니다.\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=model))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "hidden-1-drop (Dropout)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "hidden-1-drop (Dropout)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "hidden-1-drop (Dropout)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "hidden-1-drop (Dropout)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "hidden-1-drop (Dropout)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "hidden-1-drop (Dropout)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "hidden-1-drop (Dropout)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "hidden-1-drop (Dropout)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "hidden-1-drop (Dropout)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "hidden-1-drop (Dropout)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "hidden-1-drop (Dropout)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "hidden-1-drop (Dropout)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden-1 (Dense)             (None, 100)               8500      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,601\n",
      "Trainable params: 8,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x000002094F4F0A90>,\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'learning_rate': [0.01, 0.1], 'dropout_flag': [True, False], 'batch_size': [50, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid 기초 모델 정의\n",
    "def grid_base_model(learning_rate=0.01, dropout_flag=True):\n",
    "    input_dims = 84\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(input_dims,), name='input'))\n",
    "    \n",
    "    #과적합 방지를 위한 가중치와 편향에 대한 벌점항 추가\n",
    "    model.add(Dense(100, activation='relu',\n",
    "                   kernel_regularizer=regularizers.l2(0.01),\n",
    "                   bias_regularizer=regularizers.l2(0.01),\n",
    "                   name='hidden-1'))\n",
    "    \n",
    "#     model.add(Dense(100,activation='relu', name='hidden-1'))\n",
    "    \n",
    "    # 과적합 방지를 위한 dropout 추가\n",
    "    if dropout_flag :\n",
    "        model.add(Dropout(0.1, name='hidden-1-drop'))\n",
    "        \n",
    "    model.add(Dense(1, activation='sigmoid', name='output'))\n",
    "    model.summary()\n",
    "    \n",
    "    # 최적화 방법, 손실, 평가 방법 등을 정의\n",
    "    optimizer = optimizers.Adam(lr=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 모델 구성\n",
    "model = KerasClassifier(build_fn=grid_base_model, epochs=50, verbose=0)\n",
    "\n",
    "# 초모수 그리드 정의\n",
    "param_grid = dict(learning_rate=[0.01, 0.1], dropout_flag=[True, False], batch_size=[50,100])\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, return_train_score=True)\n",
    "\n",
    "# 초모수 그리드 적합\n",
    "grid_search.fit(train_x, train_y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 100, 'dropout_flag': False, 'learning_rate': 0.01}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#초모수 결정\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([17.97959956, 19.17578808, 17.34431871, 17.24404454, 16.60192649,\n",
       "        16.37138518, 12.77171516, 13.67412146]),\n",
       " 'std_fit_time': array([0.33733091, 0.1279932 , 0.44524092, 0.84612052, 1.05524248,\n",
       "        0.93645988, 0.27819395, 0.29157128]),\n",
       " 'mean_score_time': array([0.29645745, 0.45755259, 0.41711187, 0.46657713, 0.53709809,\n",
       "        0.59558376, 0.53977728, 0.65106797]),\n",
       " 'std_score_time': array([0.01023623, 0.1084696 , 0.02789525, 0.04902036, 0.04763334,\n",
       "        0.12766406, 0.01379886, 0.01885385]),\n",
       " 'param_batch_size': masked_array(data=[50, 50, 50, 50, 100, 100, 100, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_dropout_flag': masked_array(data=[True, True, False, False, True, True, False, False],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.01, 0.1, 0.01, 0.1, 0.01, 0.1, 0.01, 0.1],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'batch_size': 50, 'dropout_flag': True, 'learning_rate': 0.01},\n",
       "  {'batch_size': 50, 'dropout_flag': True, 'learning_rate': 0.1},\n",
       "  {'batch_size': 50, 'dropout_flag': False, 'learning_rate': 0.01},\n",
       "  {'batch_size': 50, 'dropout_flag': False, 'learning_rate': 0.1},\n",
       "  {'batch_size': 100, 'dropout_flag': True, 'learning_rate': 0.01},\n",
       "  {'batch_size': 100, 'dropout_flag': True, 'learning_rate': 0.1},\n",
       "  {'batch_size': 100, 'dropout_flag': False, 'learning_rate': 0.01},\n",
       "  {'batch_size': 100, 'dropout_flag': False, 'learning_rate': 0.1}],\n",
       " 'split0_test_score': array([0.72586394, 0.53742445, 0.73686657, 0.67596467, 0.71377654,\n",
       "        0.65659383, 0.7385712 , 0.52905625]),\n",
       " 'split1_test_score': array([0.73035797, 0.66496204, 0.73717651, 0.65178987, 0.73593677,\n",
       "        0.70416861, 0.73190764, 0.6144429 ]),\n",
       " 'split2_test_score': array([0.7183819 , 0.6633602 , 0.73062617, 0.69761315, 0.72814631,\n",
       "        0.60895846, 0.73620583, 0.71032238]),\n",
       " 'mean_test_score': array([0.72486827, 0.62191342, 0.73488997, 0.6751214 , 0.7259531 ,\n",
       "        0.65657609, 0.73556152, 0.61793574]),\n",
       " 'std_test_score': array([0.00493958, 0.05974862, 0.00301739, 0.01871653, 0.00917905,\n",
       "        0.03886888, 0.00275834, 0.07404184]),\n",
       " 'rank_test_score': array([4, 7, 2, 5, 3, 6, 1, 8]),\n",
       " 'split0_train_score': array([0.72475785, 0.53855095, 0.73614878, 0.67803177, 0.7134444 ,\n",
       "        0.6588919 , 0.73723363, 0.52282061]),\n",
       " 'split1_train_score': array([0.73421155, 0.65951182, 0.73808602, 0.6574971 , 0.73715614,\n",
       "        0.70925998, 0.73762108, 0.61441302]),\n",
       " 'split2_train_score': array([0.72237719, 0.65798854, 0.73361228, 0.69866729, 0.73152023,\n",
       "        0.60940648, 0.73841624, 0.71594607]),\n",
       " 'mean_train_score': array([0.72711553, 0.61868377, 0.73594902, 0.67806539, 0.72737359,\n",
       "        0.65918612, 0.73775698, 0.61772657]),\n",
       " 'std_train_score': array([0.0051109 , 0.05666587, 0.00183185, 0.01680768, 0.0101146 ,\n",
       "        0.04076555, 0.00049227, 0.07887795])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 초모수 결정을 위한 근거\n",
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# 신경망은 2차원으로 [입력층(특성), 출력층(레이블)] -> [2, 3] 으로 정합니다.\n",
    "W = tf.Variable(tf.random_uniform([84, 1], -1., 1.))\n",
    "\n",
    "# 편향을 각각 각 레이어의 아웃풋 갯수로 설정합니다.\n",
    "# 편향은 아웃풋의 갯수, 즉 최종 결과값의 분류 갯수인 3으로 설정합니다.\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "# 신경망에 가중치 W과 편향 b을 적용합니다\n",
    "L = tf.add(tf.matmul(X, W), b)\n",
    "# 가중치와 편향을 이용해 계산한 결과 값에\n",
    "# 텐서플로우에서 기본적으로 제공하는 활성화 함수인 ReLU 함수를 적용합니다.\n",
    "L = tf.nn.relu(L)\n",
    "\n",
    "# 마지막으로 softmax 함수를 이용하여 출력값을 사용하기 쉽게 만듭니다\n",
    "# softmax 함수는 다음처럼 결과값을 전체합이 1인 확률로 만들어주는 함수입니다.\n",
    "# 예) [8.04, 2.76, -6.52] -> [0.53 0.24 0.23]\n",
    "model = tf.nn.softmax(L)\n",
    "\n",
    "# 신경망을 최적화하기 위한 비용 함수를 작성합니다.\n",
    "# 각 개별 결과에 대한 합을 구한 뒤 평균을 내는 방식을 사용합니다.\n",
    "# 전체 합이 아닌, 개별 결과를 구한 뒤 평균을 내는 방식을 사용하기 위해 axis 옵션을 사용합니다.\n",
    "# axis 옵션이 없으면 -1.09 처럼 총합인 스칼라값으로 출력됩니다.\n",
    "#        Y         model         Y * tf.log(model)   reduce_sum(axis=1)\n",
    "# 예) [[1 0 0]  [[0.1 0.7 0.2]  -> [[-1.0  0    0]  -> [-1.0, -0.09]\n",
    "#     [0 1 0]]  [0.2 0.8 0.0]]     [ 0   -0.09 0]]\n",
    "# 즉, 이것은 예측값과 실제값 사이의 확률 분포의 차이를 비용으로 계산한 것이며,\n",
    "# 이것을 Cross-Entropy 라고 합니다.\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(model), axis=1))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(2):\n",
    "    sess.run(train_op, feed_dict={X: train_x, Y: train_y})\n",
    "\n",
    "    if (step + 1) % 10 == 0:\n",
    "        print(step + 1, sess.run(cost, feed_dict={X: train_x, Y: train_y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########\n",
    "# 결과 확인\n",
    "# 0: 기타 1: 포유류, 2: 조류\n",
    "######\n",
    "# tf.argmax: 예측값과 실제값의 행렬에서 tf.argmax 를 이용해 가장 큰 값을 가져옵니다.\n",
    "# 예) [[0 1 0] [1 0 0]] -> [1 0]\n",
    "#    [[0.2 0.7 0.1] [0.9 0.1 0.]] -> [1 0]\n",
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(Y, 1)\n",
    "print('예측값:', sess.run(prediction, feed_dict={X: train_x}))\n",
    "print('실제값:', sess.run(target, feed_dict={Y: train_y}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "logits and labels must be broadcastable: logits_size=[19358,2] labels_size=[1,19358]\n\t [[node softmax_cross_entropy_with_logits_1 (defined at <ipython-input-16-ae9f2108c0c2>:28) ]]\n\nCaused by op 'softmax_cross_entropy_with_logits_1', defined at:\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-16-ae9f2108c0c2>\", line 28, in <module>\n    tf.nn.softmax_cross_entropy_with_logits_v2(labels=train_y, logits=model))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2471, in softmax_cross_entropy_with_logits_v2_helper\n    precise_logits, labels, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 7861, in softmax_cross_entropy_with_logits\n    name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): logits and labels must be broadcastable: logits_size=[19358,2] labels_size=[1,19358]\n\t [[node softmax_cross_entropy_with_logits_1 (defined at <ipython-input-16-ae9f2108c0c2>:28) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: logits and labels must be broadcastable: logits_size=[19358,2] labels_size=[1,19358]\n\t [[{{node softmax_cross_entropy_with_logits_1}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ae9f2108c0c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: logits and labels must be broadcastable: logits_size=[19358,2] labels_size=[1,19358]\n\t [[node softmax_cross_entropy_with_logits_1 (defined at <ipython-input-16-ae9f2108c0c2>:28) ]]\n\nCaused by op 'softmax_cross_entropy_with_logits_1', defined at:\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-16-ae9f2108c0c2>\", line 28, in <module>\n    tf.nn.softmax_cross_entropy_with_logits_v2(labels=train_y, logits=model))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2471, in softmax_cross_entropy_with_logits_v2_helper\n    precise_logits, labels, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 7861, in softmax_cross_entropy_with_logits\n    name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): logits and labels must be broadcastable: logits_size=[19358,2] labels_size=[1,19358]\n\t [[node softmax_cross_entropy_with_logits_1 (defined at <ipython-input-16-ae9f2108c0c2>:28) ]]\n"
     ]
    }
   ],
   "source": [
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# 첫번째 가중치의 차원은 [특성, 히든 레이어의 뉴런갯수] -> [2, 10] 으로 정합니다.\n",
    "W1 = tf.Variable(tf.random_uniform([len(feature_names), 10], -1., 1.))\n",
    "# 두번째 가중치의 차원을 [첫번째 히든 레이어의 뉴런 갯수, 분류 갯수] -> [10, 3] 으로 정합니다.\n",
    "W2 = tf.Variable(tf.random_uniform([10, 2], -1., 1.))\n",
    "\n",
    "# 편향을 각각 각 레이어의 아웃풋 갯수로 설정합니다.\n",
    "# b1 은 히든 레이어의 뉴런 갯수로, b2 는 최종 결과값 즉, 분류 갯수인 3으로 설정합니다.\n",
    "b1 = tf.Variable(tf.zeros([10]))\n",
    "b2 = tf.Variable(tf.zeros([2]))\n",
    "\n",
    "# 신경망의 히든 레이어에 가중치 W1과 편향 b1을 적용합니다\n",
    "L1 = tf.add(tf.matmul(X, W1), b1)\n",
    "L1 = tf.nn.relu(L1)\n",
    "\n",
    "# 최종적인 아웃풋을 계산합니다.\n",
    "# 히든레이어에 두번째 가중치 W2와 편향 b2를 적용하여 3개의 출력값을 만들어냅니다.\n",
    "model = tf.add(tf.matmul(L1, W2), b2)\n",
    "\n",
    "# 텐서플로우에서 기본적으로 제공되는 크로스 엔트로피 함수를 이용해\n",
    "# 복잡한 수식을 사용하지 않고도 최적화를 위한 비용 함수를 다음처럼 간단하게 적용할 수 있습니다.\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=model))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(100):\n",
    "    sess.run(train_op, feed_dict={X: train_x, Y: train_y})\n",
    "\n",
    "    if (step + 1) % 10 == 0:\n",
    "        print(step + 1, sess.run(cost, feed_dict={X: test_x, Y: test_y}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 결과 확인\n",
    "# 0: 기타 1: 포유류, 2: 조류\n",
    "######\n",
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(Y, 1)\n",
    "print('예측값:', sess.run(prediction, feed_dict={X: x_data}))\n",
    "print('실제값:', sess.run(target, feed_dict={Y: y_data}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
